{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expressed-promise",
   "metadata": {},
   "source": [
    "# Classification with XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-times",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aging-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import timeit\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-genesis",
   "metadata": {},
   "source": [
    "Set the rng seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imposed-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-stand",
   "metadata": {},
   "source": [
    "## Import and view data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rapid-buffer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>FamSize</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Other</th>\n",
       "      <th>cabin_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age     Fare  FamSize  Sex_male  Embarked_Q  Embarked_S  \\\n",
       "0       0.0     3.0  22.0   7.2500      1.0       1.0         0.0         1.0   \n",
       "1       1.0     1.0  38.0  71.2833      1.0       0.0         0.0         0.0   \n",
       "2       1.0     3.0  26.0   7.9250      0.0       0.0         0.0         1.0   \n",
       "3       1.0     1.0  35.0  53.1000      1.0       0.0         0.0         1.0   \n",
       "4       0.0     3.0  35.0   8.0500      0.0       1.0         0.0         1.0   \n",
       "\n",
       "   Title_Miss  Title_Mr  Title_Mrs  Title_Other  cabin_missing  \n",
       "0         0.0       1.0        0.0          0.0            1.0  \n",
       "1         0.0       0.0        1.0          0.0            0.0  \n",
       "2         1.0       0.0        0.0          0.0            1.0  \n",
       "3         0.0       0.0        1.0          0.0            0.0  \n",
       "4         0.0       1.0        0.0          0.0            1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dims:  (891, 13)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/train_prepd.csv\")\n",
    "display(df.head())\n",
    "print('dims: ', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-panel",
   "metadata": {},
   "source": [
    "The XGBoost algorithm has default behaviour that can deal with missing data (if they are set to 0). However, I have already taken care of missing data in the EDA step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "educated-sound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived         0\n",
       "Pclass           0\n",
       "Age              0\n",
       "Fare             0\n",
       "FamSize          0\n",
       "Sex_male         0\n",
       "Embarked_Q       0\n",
       "Embarked_S       0\n",
       "Title_Miss       0\n",
       "Title_Mr         0\n",
       "Title_Mrs        0\n",
       "Title_Other      0\n",
       "cabin_missing    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-investing",
   "metadata": {},
   "source": [
    "## Split data into dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "signal-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into dependent and independent variables\n",
    "X = df.iloc[:, 1:]\n",
    "y = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-company",
   "metadata": {},
   "source": [
    "## Build a preliminary model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-pocket",
   "metadata": {},
   "source": [
    "In this step we'll build the most basic XGBoost model, to see what we can expect. First, we'll assess it on a simple train/test split, then using 10-fold cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lonely-banking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3838383838383838"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-freedom",
   "metadata": {},
   "source": [
    "The dataset is fairly imbalanced (38% survived), so we'll use stratification in the train/test split. We'll also use stratification later on for cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "comfortable-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test sets, using stratification.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-football",
   "metadata": {},
   "source": [
    "Stratification check on y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brown-nirvana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38342696629213485\n",
      "0.3854748603351955\n"
     ]
    }
   ],
   "source": [
    "# Quick check to see if samples are indeed stratified.\n",
    "print(np.mean(y_train))\n",
    "print(np.mean(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-rebel",
   "metadata": {},
   "source": [
    "Build the XGB classifier shell and fit it on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "disturbed-webmaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:51:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=12, num_parallel_tree=1, random_state=17,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_prel = xgb.XGBClassifier(use_label_encoder=False, random_state=seed)\n",
    "clf_prel.fit(X_train, y_train)\n",
    "\n",
    "# Setting use_label_encoder=False is recommended by XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-bangladesh",
   "metadata": {},
   "source": [
    "**NOTE**: In the model fit above, I could be using early stopping to prevent overfitting and improve performance - i.e. tell the algorithm to stop building more trees when the evaluation metric I choose (should be 'aucpr' here) is not improving on some holdout evaluation set (not the X_test, y_test). In the case of train/test splits, I should further split the train set into train and validation, then set early stopping criteria based on the performance gain on the validation set. In the case of CV (which occurs several times in the rest of the notebook) this is more difficult - each of the k train/test splits should really be a train/validation/test split, in order to assess early stopping on the validation set.\n",
    "\n",
    "Intermingling early stopping with Grid Search / Randomized Search CV for hyperparameter tuning doesn't seem a great idea. \n",
    "\n",
    "https://stackoverflow.com/questions/48127550/early-stopping-with-keras-and-sklearn-gridsearchcv-cross-validation\n",
    "\n",
    "Once I have the best hyperparameters through CV, I can always employ early stopping when fitting the model in the whole training set (provided of course that there is a separate validation set). Given the small size of the dataset for this project, I would prefer not to split further the training set just to employ early stopping.\n",
    "\n",
    "A script is nonetheless constructed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split into train, validation and test sets in order to use early stopping.\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state = seed)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, stratify=y_train, random_state=seed) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "\n",
    "# # Stratification check.\n",
    "\n",
    "#print(np.mean(y_train))\n",
    "#print(np.mean(y_test))\n",
    "#print(np.mean(y_val))\n",
    "\n",
    "\n",
    "# Build the XGB classifier shell and fit it on the training data. First, without early stopping. Evaluate on the validation set using AUC PR.\n",
    "\n",
    "# **NOTE**: It is commonly seen to evaluate early stopping on the test set. This results in data leakage.\n",
    "\n",
    "#clf_prel = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, random_state=seed)\n",
    "#clf_prel.fit(X_train, \n",
    "#             y_train,\n",
    "#             verbose=True,\n",
    "#             #early_stopping_rounds=XX,\n",
    "#             eval_metric='aucpr',\n",
    "#             eval_set=[(X_train, y_train), (X_val, y_val)])\n",
    "\n",
    "# # Setting use_label_encoder=False is recommended by XGBoost.\n",
    "\n",
    "# # If multiple evaluation datasets or multiple evaluation metrics are provided, then early stopping will use the last in the list.\n",
    "\n",
    "\n",
    "# Plot performance on the training set and on the validation set as more trees are built.\n",
    "\n",
    "# results = clf_prel.evals_result()\n",
    "# epochs = len(results['validation_0']['aucpr'])\n",
    "# x_axis = range(0, epochs)\n",
    "# # plot AUC PR\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x_axis, results['validation_0']['aucpr'], label='Train')\n",
    "# ax.plot(x_axis, results['validation_1']['aucpr'], label='Validation')\n",
    "# ax.legend()\n",
    "# plt.ylabel('AUC PR')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.title('XGBoost AUC PR')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Clearly the algorithm overfits quite fast. We will fit again using early stopping after no improvement is found on the validation set after 10 trees.\n",
    "\n",
    "# clf_prel = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, random_state=seed)\n",
    "# clf_prel.fit(X_train, \n",
    "#              y_train,\n",
    "#              verbose=True,\n",
    "#              early_stopping_rounds=10,\n",
    "#              eval_metric='aucpr',\n",
    "#              eval_set=[(X_train, y_train), (X_val, y_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "complimentary-involvement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.68 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x130ffe703a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict on the test set\n",
    "y_pred = clf_prel.predict(X_test)\n",
    "\n",
    "# print accuracy and draw the confusion matrix\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Accuracy: {:.2f} %'.format(acc * 100))\n",
    "\n",
    "plot_confusion_matrix(clf_prel, \n",
    "                     X_test,\n",
    "                     y_test, display_labels=['Did not survive', 'Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-anderson",
   "metadata": {},
   "source": [
    "Get a more robust estimation of the model accuracy, using repeated 10-fold stratified cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "natural-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "scores:  [0.84444444 0.83146067 0.82022472 0.80898876 0.83146067 0.84269663\n",
      " 0.86516854 0.84269663 0.85393258 0.84269663 0.82222222 0.84269663\n",
      " 0.80898876 0.8988764  0.8988764  0.83146067 0.7752809  0.85393258\n",
      " 0.87640449 0.82022472 0.9        0.7752809  0.83146067 0.83146067\n",
      " 0.88764045 0.7752809  0.87640449 0.86516854 0.84269663 0.85393258\n",
      " 0.83333333 0.83146067 0.85393258 0.80898876 0.80898876 0.85393258\n",
      " 0.86516854 0.86516854 0.85393258 0.82022472 0.84444444 0.85393258\n",
      " 0.80898876 0.84269663 0.82022472 0.82022472 0.85393258 0.83146067\n",
      " 0.83146067 0.87640449]\n",
      "Accuracy: 84.06 %\n",
      "St.dev: 0.0287\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=seed)\n",
    "scores = cross_val_score(clf_prel, X, y, cv=cv)\n",
    "\n",
    "print('scores: ', scores )\n",
    "print('Accuracy: {:.2f} %'.format(scores.mean() * 100))\n",
    "print('St.dev: {:.4f}'.format(scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-genealogy",
   "metadata": {},
   "source": [
    "The preliminary model has an accuracy of 84.06%. We'll see if we can improve it with hypermarameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-pastor",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-reset",
   "metadata": {},
   "source": [
    "We will use Grid Search CV (and Randomized Search CV) to find the best hyperparameters for XGBoost. Grid Search CV is going to be run within the entire training set and the model with the best average performance on the validation sets will be picked. Early stopping is not used (see note above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "virgin-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the parameters dictionary\n",
    "param_grid = {\n",
    "    'max_depth': [4, 6, 8, 10], #increasing max depth further will likely improve performance, but will lead to overfitting.\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3, 0.5], #learning rate 0.01 will likely overfit\n",
    "    'gamma': [0, 0.25, 0.5, 1],\n",
    "    'reg_lambda': [0, 1, 10, 20],\n",
    "    'scale_pos_weight': [1, 2, 3, 4], #XGBoost recommends sum(negative instances) / sum(positive instances)\n",
    "    'colsample_bytree': [0.3, 0.5, 0.8, 1],\n",
    "    'min_child_weight': [1, 3, 5, 7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "common-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the XGB classifier shell and pass it to grid search along with the parameters dictionary\n",
    "clf_gs = xgb.XGBClassifier(use_label_encoder=False, random_state=seed)\n",
    "gs = GridSearchCV(clf_gs, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  n_jobs=-1, \n",
    "                  cv=5, \n",
    "                  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "interested-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rs = xgb.XGBClassifier(use_label_encoder=False, random_state=seed)\n",
    "rs = RandomizedSearchCV(estimator=clf_rs,\n",
    "                        param_distributions=param_grid,\n",
    "                        scoring='accuracy',\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=500,\n",
    "                        cv=5,\n",
    "                        verbose=2,\n",
    "                        random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-cheat",
   "metadata": {},
   "source": [
    "First with Grid Search CV, which is exhaustive and more performance intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "animated-chick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24576 candidates, totalling 122880 fits\n",
      "[22:38:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best Accuracy: 86.31 %\n",
      "Best Parameters:  {'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.3, 'max_depth': 8, 'min_child_weight': 3, 'reg_lambda': 1, 'scale_pos_weight': 1}\n",
      "Time: 2697.25\n"
     ]
    }
   ],
   "source": [
    "#start timer\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#run grid cv and print parameters\n",
    "gs.fit(X, y)\n",
    "print(\"Best Accuracy: {:.2f} %\".format(gs.best_score_*100))\n",
    "print(\"Best Parameters: \", gs.best_params_)\n",
    "\n",
    "#end timer and print\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {:.2f}'.format(stop - start)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "thrown-attribute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>param_scale_pos_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11924</th>\n",
       "      <td>0.252830</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.00049</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 1, 'learnin...</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.893258</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.863091</td>\n",
       "      <td>0.022811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21320</th>\n",
       "      <td>0.285459</td>\n",
       "      <td>0.012949</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.00049</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 1, 'gamma': 0.25, 'learni...</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.893258</td>\n",
       "      <td>0.863085</td>\n",
       "      <td>0.024713</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16544</th>\n",
       "      <td>0.266642</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.00049</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'gamma': 0.5, 'learn...</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.870787</td>\n",
       "      <td>0.861967</td>\n",
       "      <td>0.015988</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10468</th>\n",
       "      <td>0.230609</td>\n",
       "      <td>0.005648</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.00049</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 0.5, 'gamma': 0.5, 'learn...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.887640</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.860850</td>\n",
       "      <td>0.021586</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16872</th>\n",
       "      <td>0.239818</td>\n",
       "      <td>0.008762</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.00049</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'gamma': 0.5, 'learn...</td>\n",
       "      <td>0.843575</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.860850</td>\n",
       "      <td>0.015451</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "11924       0.252830      0.003444         0.002602         0.00049   \n",
       "21320       0.285459      0.012949         0.002602         0.00049   \n",
       "16544       0.266642      0.005540         0.002602         0.00049   \n",
       "10468       0.230609      0.005648         0.002602         0.00049   \n",
       "16872       0.239818      0.008762         0.002602         0.00049   \n",
       "\n",
       "      param_colsample_bytree param_gamma param_learning_rate param_max_depth  \\\n",
       "11924                    0.5           1                 0.3               8   \n",
       "21320                      1        0.25                 0.5               6   \n",
       "16544                    0.8         0.5                 0.3               8   \n",
       "10468                    0.5         0.5                 0.3              10   \n",
       "16872                    0.8         0.5                 0.5              10   \n",
       "\n",
       "      param_min_child_weight param_reg_lambda param_scale_pos_weight  \\\n",
       "11924                      3                1                      1   \n",
       "21320                      1               10                      1   \n",
       "16544                      5                0                      1   \n",
       "10468                      5                1                      1   \n",
       "16872                      5               10                      1   \n",
       "\n",
       "                                                  params  split0_test_score  \\\n",
       "11924  {'colsample_bytree': 0.5, 'gamma': 1, 'learnin...           0.849162   \n",
       "21320  {'colsample_bytree': 1, 'gamma': 0.25, 'learni...           0.854749   \n",
       "16544  {'colsample_bytree': 0.8, 'gamma': 0.5, 'learn...           0.849162   \n",
       "10468  {'colsample_bytree': 0.5, 'gamma': 0.5, 'learn...           0.843575   \n",
       "16872  {'colsample_bytree': 0.8, 'gamma': 0.5, 'learn...           0.843575   \n",
       "\n",
       "       split1_test_score  split2_test_score  split3_test_score  \\\n",
       "11924           0.837079           0.893258           0.848315   \n",
       "21320           0.825843           0.887640           0.853933   \n",
       "16544           0.842697           0.887640           0.859551   \n",
       "10468           0.831461           0.887640           0.859551   \n",
       "16872           0.853933           0.882022           0.848315   \n",
       "\n",
       "       split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "11924           0.887640         0.863091        0.022811                1  \n",
       "21320           0.893258         0.863085        0.024713                2  \n",
       "16544           0.870787         0.861967        0.015988                3  \n",
       "10468           0.882022         0.860850        0.021586                4  \n",
       "16872           0.876404         0.860850        0.015451                5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results in a dataframe\n",
    "pd.DataFrame(gs.cv_results_).sort_values(by='rank_test_score').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-spray",
   "metadata": {},
   "source": [
    "Then with Randomized Search CV, which samples the hypermarameter combinations and should be much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "altered-resistance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "[22:42:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best Accuracy: 85.86 %\n",
      "Best Parameters:  {'scale_pos_weight': 1, 'reg_lambda': 0, 'min_child_weight': 3, 'max_depth': 4, 'learning_rate': 0.3, 'gamma': 0, 'colsample_bytree': 0.5}\n",
      "Time: 53.02\n"
     ]
    }
   ],
   "source": [
    "#start timer\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#run grid cv and print parameters\n",
    "rs.fit(X, y)\n",
    "print(\"Best Accuracy: {:.2f} %\".format(rs.best_score_*100))\n",
    "print(\"Best Parameters: \", rs.best_params_)\n",
    "\n",
    "#end timer and print\n",
    "stop = timeit.default_timer()\n",
    "print('Time: {:.2f}'.format(stop - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "shared-fifteen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_scale_pos_weight</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>param_min_child_weight</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.166551</td>\n",
       "      <td>0.011012</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>1.168008e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'scale_pos_weight': 1, 'reg_lambda': 0, 'min_...</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.904494</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.858596</td>\n",
       "      <td>0.026143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.178962</td>\n",
       "      <td>0.010694</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>4.002095e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'scale_pos_weight': 1, 'reg_lambda': 0, 'min_...</td>\n",
       "      <td>0.871508</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.870787</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.858571</td>\n",
       "      <td>0.011617</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.255031</td>\n",
       "      <td>0.015447</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>4.902129e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>{'scale_pos_weight': 1, 'reg_lambda': 1, 'min_...</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.857467</td>\n",
       "      <td>0.020263</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.301874</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>4.904075e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'scale_pos_weight': 1, 'reg_lambda': 1, 'min_...</td>\n",
       "      <td>0.849162</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.856349</td>\n",
       "      <td>0.016816</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.252830</td>\n",
       "      <td>0.010810</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>4.903686e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'scale_pos_weight': 1, 'reg_lambda': 1, 'min_...</td>\n",
       "      <td>0.854749</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.856343</td>\n",
       "      <td>0.013079</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "277       0.166551      0.011012         0.002002    1.168008e-07   \n",
       "407       0.178962      0.010694         0.002202    4.002095e-04   \n",
       "403       0.255031      0.015447         0.002402    4.902129e-04   \n",
       "56        0.301874      0.003009         0.002602    4.904075e-04   \n",
       "399       0.252830      0.010810         0.002602    4.903686e-04   \n",
       "\n",
       "    param_scale_pos_weight param_reg_lambda param_min_child_weight  \\\n",
       "277                      1                0                      3   \n",
       "407                      1                0                      3   \n",
       "403                      1                1                      5   \n",
       "56                       1                1                      3   \n",
       "399                      1                1                      5   \n",
       "\n",
       "    param_max_depth param_learning_rate param_gamma param_colsample_bytree  \\\n",
       "277               4                 0.3           0                    0.5   \n",
       "407               4                 0.3         0.5                      1   \n",
       "403               6                 0.2        0.25                      1   \n",
       "56                8                 0.1           0                    0.5   \n",
       "399              10                 0.2         0.5                    0.5   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "277  {'scale_pos_weight': 1, 'reg_lambda': 0, 'min_...           0.849162   \n",
       "407  {'scale_pos_weight': 1, 'reg_lambda': 0, 'min_...           0.871508   \n",
       "403  {'scale_pos_weight': 1, 'reg_lambda': 1, 'min_...           0.854749   \n",
       "56   {'scale_pos_weight': 1, 'reg_lambda': 1, 'min_...           0.849162   \n",
       "399  {'scale_pos_weight': 1, 'reg_lambda': 1, 'min_...           0.854749   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "277           0.825843           0.904494           0.848315   \n",
       "407           0.842697           0.870787           0.848315   \n",
       "403           0.825843           0.876404           0.848315   \n",
       "56            0.837079           0.876404           0.842697   \n",
       "399           0.842697           0.876404           0.842697   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "277           0.865169         0.858596        0.026143                1  \n",
       "407           0.859551         0.858571        0.011617                2  \n",
       "403           0.882022         0.857467        0.020263                3  \n",
       "56            0.876404         0.856349        0.016816                4  \n",
       "399           0.865169         0.856343        0.013079                5  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results in a dataframe\n",
    "pd.DataFrame(rs.cv_results_).sort_values(by='rank_test_score').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-billion",
   "metadata": {},
   "source": [
    "## Final XGBoost model and evaluation on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-johnston",
   "metadata": {},
   "source": [
    "Here we build the final XGB model, with the optimized hyperparameters from Grid Search CV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "surgical-words",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:45:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5, gamma=1, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=8,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=12, num_parallel_tree=1, random_state=17,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(colsample_bytree=0.5,\n",
    "                        gamma=1,\n",
    "                        learning_rate=0.3,\n",
    "                        max_depth=8,\n",
    "                        min_child_weight=3,\n",
    "                        reg_lambda=1,\n",
    "                        scale_pos_weight=1,\n",
    "                        use_label_encoder=False,\n",
    "                        random_state=seed\n",
    "                        )\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deadly-oakland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.36 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1310bc28ee0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# print accuracy and draw the confusion matrix\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Accuracy: {:.2f} %'.format(acc * 100))\n",
    "\n",
    "plot_confusion_matrix(clf, \n",
    "                     X_test,\n",
    "                     y_test, display_labels=['Did not survive', 'Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-suggestion",
   "metadata": {},
   "source": [
    "Finally, evaluate the performance using repeated 10-fold stratified cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "personal-biography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:46:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "scores:  [0.83333333 0.8988764  0.79775281 0.85393258 0.85393258 0.83146067\n",
      " 0.83146067 0.84269663 0.86516854 0.84269663 0.83333333 0.82022472\n",
      " 0.79775281 0.88764045 0.86516854 0.85393258 0.78651685 0.84269663\n",
      " 0.8988764  0.82022472 0.87777778 0.80898876 0.80898876 0.85393258\n",
      " 0.84269663 0.80898876 0.92134831 0.84269663 0.84269663 0.79775281\n",
      " 0.84444444 0.83146067 0.84269663 0.82022472 0.85393258 0.86516854\n",
      " 0.85393258 0.80898876 0.87640449 0.86516854 0.82222222 0.84269663\n",
      " 0.84269663 0.85393258 0.78651685 0.83146067 0.88764045 0.84269663\n",
      " 0.85393258 0.8988764 ]\n",
      "Accuracy: 84.38 %\n",
      "St.dev: 0.0299\n"
     ]
    }
   ],
   "source": [
    "# Create the cv tactic (repeated and stratified 10-fold).\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=seed)\n",
    "\n",
    "# Get the scores and return the output.\n",
    "scores = cross_val_score(clf, X, y, cv=cv)\n",
    "\n",
    "print('scores: ', scores )\n",
    "print('Accuracy: {:.2f} %'.format(scores.mean() * 100))\n",
    "print('St.dev: {:.4f}'.format(scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-beauty",
   "metadata": {},
   "source": [
    "CV results show that we can expect an accuracy of 84.4% from the tuned XGBoost. This is about 0.4% increase from the preliminary model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
